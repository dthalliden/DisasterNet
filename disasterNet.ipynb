{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "disasterNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "URbgPrlAy3Hh"
      },
      "source": [
        "import keras\n",
        "from tensorflow.keras.applications import ResNet50V2\n",
        "import zipfile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sf-5SW30co7",
        "outputId": "a6e49ca0-7593-4506-8bb3-61360ac740f5"
      },
      "source": [
        "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/Colab Notebooks/AIDER.zip\", 'r')\n",
        "zip_ref.extractall(\"/tmp\")\n",
        "zip_ref.close()\n",
        "\n",
        "dataGenerator = keras.preprocessing.image.ImageDataGenerator(validation_split = 0.3, samplewise_center = True)\n",
        "\n",
        "test = dataGenerator.flow_from_directory(\"/tmp/AIDER\", class_mode='categorical', target_size = (256,256), batch_size=28, subset=\"validation\", shuffle=True)\n",
        "train = dataGenerator.flow_from_directory(\"/tmp/AIDER\", class_mode='categorical', target_size = (256,256), batch_size=28, subset=\"training\", shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1626 images belonging to 3 classes.\n",
            "Found 3796 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "j86iYk3PLuVY",
        "outputId": "98556c39-d612-461f-cdb9-078e5c01cede"
      },
      "source": [
        "def disasterNet():\n",
        "  \n",
        "    model = keras.models.Sequential()\n",
        "    #model.add(keras.layers.experimental.preprocessing.Normalization())\n",
        "    model.add(keras.layers.experimental.preprocessing.RandomRotation(1,input_shape = (256,256,3)))\n",
        "    model.add(keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"))\n",
        "    model.add(keras.layers.experimental.preprocessing.RandomFlip(\"vertical\"))\n",
        "    model.add(keras.layers.experimental.preprocessing.RandomZoom(0.2))\n",
        "    model.add(keras.layers.experimental.preprocessing.RandomTranslation(height_factor = 0.1, width_factor = 0.1))\n",
        "    model.add(ResNet50V2(include_top = False, weights = \"imagenet\", input_tensor = keras.Input(shape = (256, 256, 3))))\n",
        "    model.add(keras.layers.GlobalAveragePooling2D())\n",
        "    model.add(keras.layers.Dropout(0.2))\n",
        "    model.add(keras.layers.Dense(256, activation = \"relu\"))\n",
        "    model.add(keras.layers.Dropout(0.4))\n",
        "    model.add(keras.layers.Dense(256, activation = \"relu\"))\n",
        "    model.add(keras.layers.Dropout(0.6))\n",
        "    model.add(keras.layers.Dense(3, activation = \"softmax\"))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.SGD(learning_rate = 0.001), metrics=[\"categorical_accuracy\"])\n",
        "    \n",
        "    return(model)\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
        "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, min_delta=1e-4, mode='min')\n",
        "\n",
        "model = disasterNet()\n",
        "model.summary()\n",
        "#model.fit(train, epochs=100, validation_data=test, class_weight = {0:1, 1:5, 2:1})\n",
        "model.fit(train, epochs=100, validation_data=test, callbacks=[mcp_save, reduce_lr_loss])\n",
        "\n",
        "#IMPORTANT: Your model must be saved as \"Q3.h5\"\n",
        "model.save(\"./Q3.h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "random_rotation_2 (RandomRot (None, 256, 256, 3)       0         \n",
            "_________________________________________________________________\n",
            "random_flip_4 (RandomFlip)   (None, 256, 256, 3)       0         \n",
            "_________________________________________________________________\n",
            "random_flip_5 (RandomFlip)   (None, 256, 256, 3)       0         \n",
            "_________________________________________________________________\n",
            "random_zoom_2 (RandomZoom)   (None, 256, 256, 3)       0         \n",
            "_________________________________________________________________\n",
            "random_translation_2 (Random (None, 256, 256, 3)       0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 8, 8, 2048)        23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 256)               524544    \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 3)                 771       \n",
            "=================================================================\n",
            "Total params: 24,155,907\n",
            "Trainable params: 24,110,467\n",
            "Non-trainable params: 45,440\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "136/136 [==============================] - 32s 197ms/step - loss: 1.2102 - categorical_accuracy: 0.4581 - val_loss: 0.5730 - val_categorical_accuracy: 0.8100\n",
            "Epoch 2/100\n",
            "136/136 [==============================] - 26s 191ms/step - loss: 0.7034 - categorical_accuracy: 0.7592 - val_loss: 0.4889 - val_categorical_accuracy: 0.8100\n",
            "Epoch 3/100\n",
            "136/136 [==============================] - 26s 190ms/step - loss: 0.6006 - categorical_accuracy: 0.7958 - val_loss: 0.4279 - val_categorical_accuracy: 0.8100\n",
            "Epoch 4/100\n",
            "136/136 [==============================] - 26s 190ms/step - loss: 0.5303 - categorical_accuracy: 0.8052 - val_loss: 0.3862 - val_categorical_accuracy: 0.8130\n",
            "Epoch 5/100\n",
            "136/136 [==============================] - 26s 190ms/step - loss: 0.5203 - categorical_accuracy: 0.8084 - val_loss: 0.3543 - val_categorical_accuracy: 0.8216\n",
            "Epoch 6/100\n",
            "136/136 [==============================] - 26s 190ms/step - loss: 0.4642 - categorical_accuracy: 0.8193 - val_loss: 0.3173 - val_categorical_accuracy: 0.8506\n",
            "Epoch 7/100\n",
            "136/136 [==============================] - 26s 189ms/step - loss: 0.4095 - categorical_accuracy: 0.8432 - val_loss: 0.2830 - val_categorical_accuracy: 0.8739\n",
            "Epoch 8/100\n",
            "136/136 [==============================] - 26s 190ms/step - loss: 0.3671 - categorical_accuracy: 0.8668 - val_loss: 0.2590 - val_categorical_accuracy: 0.8918\n",
            "Epoch 9/100\n",
            "136/136 [==============================] - 26s 191ms/step - loss: 0.3329 - categorical_accuracy: 0.8763 - val_loss: 0.2282 - val_categorical_accuracy: 0.9127\n",
            "Epoch 10/100\n",
            "136/136 [==============================] - 26s 190ms/step - loss: 0.3279 - categorical_accuracy: 0.8758 - val_loss: 0.2027 - val_categorical_accuracy: 0.9244\n",
            "Epoch 11/100\n",
            "136/136 [==============================] - 26s 193ms/step - loss: 0.2755 - categorical_accuracy: 0.8998 - val_loss: 0.1808 - val_categorical_accuracy: 0.9354\n",
            "Epoch 12/100\n",
            "136/136 [==============================] - 27s 199ms/step - loss: 0.2554 - categorical_accuracy: 0.9167 - val_loss: 0.1749 - val_categorical_accuracy: 0.9397\n",
            "Epoch 13/100\n",
            "136/136 [==============================] - 27s 199ms/step - loss: 0.2434 - categorical_accuracy: 0.9215 - val_loss: 0.1591 - val_categorical_accuracy: 0.9483\n",
            "Epoch 14/100\n",
            "136/136 [==============================] - 27s 197ms/step - loss: 0.2358 - categorical_accuracy: 0.9185 - val_loss: 0.1534 - val_categorical_accuracy: 0.9533\n",
            "Epoch 15/100\n",
            "136/136 [==============================] - 27s 195ms/step - loss: 0.2056 - categorical_accuracy: 0.9329 - val_loss: 0.1439 - val_categorical_accuracy: 0.9551\n",
            "Epoch 16/100\n",
            "136/136 [==============================] - 26s 194ms/step - loss: 0.1955 - categorical_accuracy: 0.9376 - val_loss: 0.1375 - val_categorical_accuracy: 0.9576\n",
            "Epoch 17/100\n",
            "136/136 [==============================] - 26s 192ms/step - loss: 0.1812 - categorical_accuracy: 0.9422 - val_loss: 0.1365 - val_categorical_accuracy: 0.9600\n",
            "Epoch 18/100\n",
            "136/136 [==============================] - 26s 194ms/step - loss: 0.1847 - categorical_accuracy: 0.9396 - val_loss: 0.1378 - val_categorical_accuracy: 0.9600\n",
            "Epoch 19/100\n",
            "136/136 [==============================] - 26s 192ms/step - loss: 0.1847 - categorical_accuracy: 0.9348 - val_loss: 0.1318 - val_categorical_accuracy: 0.9600\n",
            "Epoch 20/100\n",
            "136/136 [==============================] - 26s 193ms/step - loss: 0.1500 - categorical_accuracy: 0.9532 - val_loss: 0.1217 - val_categorical_accuracy: 0.9637\n",
            "Epoch 21/100\n",
            "136/136 [==============================] - 26s 194ms/step - loss: 0.1574 - categorical_accuracy: 0.9511 - val_loss: 0.1282 - val_categorical_accuracy: 0.9631\n",
            "Epoch 22/100\n",
            "136/136 [==============================] - 26s 193ms/step - loss: 0.1433 - categorical_accuracy: 0.9533 - val_loss: 0.1218 - val_categorical_accuracy: 0.9643\n",
            "Epoch 23/100\n",
            "136/136 [==============================] - 26s 193ms/step - loss: 0.1441 - categorical_accuracy: 0.9554 - val_loss: 0.1224 - val_categorical_accuracy: 0.9668\n",
            "Epoch 24/100\n",
            "136/136 [==============================] - 26s 193ms/step - loss: 0.1357 - categorical_accuracy: 0.9544 - val_loss: 0.1323 - val_categorical_accuracy: 0.9637\n",
            "Epoch 25/100\n",
            "136/136 [==============================] - 26s 192ms/step - loss: 0.1199 - categorical_accuracy: 0.9597 - val_loss: 0.1441 - val_categorical_accuracy: 0.9643\n",
            "Epoch 26/100\n",
            "136/136 [==============================] - 26s 189ms/step - loss: 0.1244 - categorical_accuracy: 0.9577 - val_loss: 0.1292 - val_categorical_accuracy: 0.9656\n",
            "Epoch 27/100\n",
            "136/136 [==============================] - 26s 190ms/step - loss: 0.1246 - categorical_accuracy: 0.9568 - val_loss: 0.1256 - val_categorical_accuracy: 0.9668\n",
            "\n",
            "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Epoch 28/100\n",
            "136/136 [==============================] - 26s 188ms/step - loss: 0.1392 - categorical_accuracy: 0.9512 - val_loss: 0.1230 - val_categorical_accuracy: 0.9668\n",
            "Epoch 29/100\n",
            "136/136 [==============================] - 26s 189ms/step - loss: 0.1164 - categorical_accuracy: 0.9604 - val_loss: 0.1181 - val_categorical_accuracy: 0.9680\n",
            "Epoch 30/100\n",
            "136/136 [==============================] - 26s 191ms/step - loss: 0.1253 - categorical_accuracy: 0.9616 - val_loss: 0.1178 - val_categorical_accuracy: 0.9680\n",
            "Epoch 31/100\n",
            "136/136 [==============================] - 26s 192ms/step - loss: 0.1244 - categorical_accuracy: 0.9586 - val_loss: 0.1214 - val_categorical_accuracy: 0.9680\n",
            "Epoch 32/100\n",
            "136/136 [==============================] - 26s 192ms/step - loss: 0.1315 - categorical_accuracy: 0.9591 - val_loss: 0.1197 - val_categorical_accuracy: 0.9680\n",
            "Epoch 33/100\n",
            "136/136 [==============================] - 26s 190ms/step - loss: 0.1234 - categorical_accuracy: 0.9573 - val_loss: 0.1216 - val_categorical_accuracy: 0.9668\n",
            "Epoch 34/100\n",
            "136/136 [==============================] - 26s 190ms/step - loss: 0.1199 - categorical_accuracy: 0.9562 - val_loss: 0.1224 - val_categorical_accuracy: 0.9668\n",
            "Epoch 35/100\n",
            "136/136 [==============================] - 26s 189ms/step - loss: 0.1274 - categorical_accuracy: 0.9593 - val_loss: 0.1236 - val_categorical_accuracy: 0.9674\n",
            "Epoch 36/100\n",
            "136/136 [==============================] - 26s 189ms/step - loss: 0.1380 - categorical_accuracy: 0.9553 - val_loss: 0.1211 - val_categorical_accuracy: 0.9674\n",
            "Epoch 37/100\n",
            "136/136 [==============================] - 26s 189ms/step - loss: 0.1246 - categorical_accuracy: 0.9610 - val_loss: 0.1207 - val_categorical_accuracy: 0.9686\n",
            "\n",
            "Epoch 00037: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Epoch 38/100\n",
            "136/136 [==============================] - 26s 187ms/step - loss: 0.1295 - categorical_accuracy: 0.9527 - val_loss: 0.1191 - val_categorical_accuracy: 0.9680\n",
            "Epoch 39/100\n",
            "136/136 [==============================] - 26s 188ms/step - loss: 0.1120 - categorical_accuracy: 0.9668 - val_loss: 0.1208 - val_categorical_accuracy: 0.9686\n",
            "Epoch 40/100\n",
            "136/136 [==============================] - 26s 189ms/step - loss: 0.1168 - categorical_accuracy: 0.9596 - val_loss: 0.1220 - val_categorical_accuracy: 0.9692\n",
            "Epoch 41/100\n",
            "136/136 [==============================] - 26s 188ms/step - loss: 0.1156 - categorical_accuracy: 0.9633 - val_loss: 0.1234 - val_categorical_accuracy: 0.9680\n",
            "Epoch 42/100\n",
            "136/136 [==============================] - 26s 189ms/step - loss: 0.1294 - categorical_accuracy: 0.9548 - val_loss: 0.1220 - val_categorical_accuracy: 0.9674\n",
            "Epoch 43/100\n",
            "136/136 [==============================] - 26s 189ms/step - loss: 0.1285 - categorical_accuracy: 0.9670 - val_loss: 0.1221 - val_categorical_accuracy: 0.9692\n",
            "Epoch 44/100\n",
            "136/136 [==============================] - 26s 188ms/step - loss: 0.1198 - categorical_accuracy: 0.9603 - val_loss: 0.1224 - val_categorical_accuracy: 0.9674\n",
            "\n",
            "Epoch 00044: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "Epoch 45/100\n",
            "136/136 [==============================] - 26s 187ms/step - loss: 0.1220 - categorical_accuracy: 0.9634 - val_loss: 0.1244 - val_categorical_accuracy: 0.9674\n",
            "Epoch 46/100\n",
            "136/136 [==============================] - 26s 190ms/step - loss: 0.1286 - categorical_accuracy: 0.9591 - val_loss: 0.1231 - val_categorical_accuracy: 0.9674\n",
            "Epoch 47/100\n",
            "136/136 [==============================] - 26s 188ms/step - loss: 0.1270 - categorical_accuracy: 0.9573 - val_loss: 0.1217 - val_categorical_accuracy: 0.9692\n",
            "Epoch 48/100\n",
            "136/136 [==============================] - 26s 190ms/step - loss: 0.1160 - categorical_accuracy: 0.9641 - val_loss: 0.1183 - val_categorical_accuracy: 0.9680\n",
            "Epoch 49/100\n",
            "136/136 [==============================] - 26s 192ms/step - loss: 0.1264 - categorical_accuracy: 0.9635 - val_loss: 0.1196 - val_categorical_accuracy: 0.9692\n",
            "Epoch 50/100\n",
            "136/136 [==============================] - 27s 195ms/step - loss: 0.1075 - categorical_accuracy: 0.9674 - val_loss: 0.1216 - val_categorical_accuracy: 0.9686\n",
            "Epoch 51/100\n",
            "136/136 [==============================] - 27s 198ms/step - loss: 0.1108 - categorical_accuracy: 0.9636 - val_loss: 0.1207 - val_categorical_accuracy: 0.9686\n",
            "\n",
            "Epoch 00051: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
            "Epoch 52/100\n",
            "136/136 [==============================] - 26s 193ms/step - loss: 0.1292 - categorical_accuracy: 0.9547 - val_loss: 0.1205 - val_categorical_accuracy: 0.9686\n",
            "Epoch 53/100\n",
            "136/136 [==============================] - 26s 194ms/step - loss: 0.1243 - categorical_accuracy: 0.9640 - val_loss: 0.1207 - val_categorical_accuracy: 0.9692\n",
            "Epoch 54/100\n",
            "136/136 [==============================] - 26s 194ms/step - loss: 0.1489 - categorical_accuracy: 0.9457 - val_loss: 0.1197 - val_categorical_accuracy: 0.9692\n",
            "Epoch 55/100\n",
            "136/136 [==============================] - 26s 192ms/step - loss: 0.1075 - categorical_accuracy: 0.9631 - val_loss: 0.1216 - val_categorical_accuracy: 0.9674\n",
            "Epoch 56/100\n",
            "136/136 [==============================] - 26s 192ms/step - loss: 0.1135 - categorical_accuracy: 0.9618 - val_loss: 0.1229 - val_categorical_accuracy: 0.9680\n",
            "Epoch 57/100\n",
            "136/136 [==============================] - 26s 192ms/step - loss: 0.1213 - categorical_accuracy: 0.9584 - val_loss: 0.1163 - val_categorical_accuracy: 0.9699\n",
            "Epoch 58/100\n",
            "136/136 [==============================] - 27s 196ms/step - loss: 0.1039 - categorical_accuracy: 0.9645 - val_loss: 0.1216 - val_categorical_accuracy: 0.9674\n",
            "Epoch 59/100\n",
            "136/136 [==============================] - 27s 196ms/step - loss: 0.1335 - categorical_accuracy: 0.9580 - val_loss: 0.1213 - val_categorical_accuracy: 0.9692\n",
            "Epoch 60/100\n",
            "136/136 [==============================] - 27s 195ms/step - loss: 0.1249 - categorical_accuracy: 0.9601 - val_loss: 0.1189 - val_categorical_accuracy: 0.9699\n",
            "Epoch 61/100\n",
            "136/136 [==============================] - 26s 193ms/step - loss: 0.1069 - categorical_accuracy: 0.9654 - val_loss: 0.1229 - val_categorical_accuracy: 0.9686\n",
            "Epoch 62/100\n",
            "136/136 [==============================] - 27s 195ms/step - loss: 0.1298 - categorical_accuracy: 0.9572 - val_loss: 0.1213 - val_categorical_accuracy: 0.9686\n",
            "Epoch 63/100\n",
            "136/136 [==============================] - 26s 193ms/step - loss: 0.1113 - categorical_accuracy: 0.9638 - val_loss: 0.1231 - val_categorical_accuracy: 0.9680\n",
            "Epoch 64/100\n",
            "136/136 [==============================] - 27s 195ms/step - loss: 0.1073 - categorical_accuracy: 0.9614 - val_loss: 0.1228 - val_categorical_accuracy: 0.9680\n",
            "\n",
            "Epoch 00064: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
            "Epoch 65/100\n",
            "136/136 [==============================] - 26s 192ms/step - loss: 0.1047 - categorical_accuracy: 0.9606 - val_loss: 0.1220 - val_categorical_accuracy: 0.9674\n",
            "Epoch 66/100\n",
            "136/136 [==============================] - 26s 194ms/step - loss: 0.1084 - categorical_accuracy: 0.9648 - val_loss: 0.1220 - val_categorical_accuracy: 0.9668\n",
            "Epoch 67/100\n",
            "136/136 [==============================] - 26s 193ms/step - loss: 0.1063 - categorical_accuracy: 0.9647 - val_loss: 0.1212 - val_categorical_accuracy: 0.9692\n",
            "Epoch 68/100\n",
            "136/136 [==============================] - 26s 194ms/step - loss: 0.1126 - categorical_accuracy: 0.9647 - val_loss: 0.1245 - val_categorical_accuracy: 0.9668\n",
            "Epoch 69/100\n",
            "136/136 [==============================] - 26s 193ms/step - loss: 0.1239 - categorical_accuracy: 0.9607 - val_loss: 0.1223 - val_categorical_accuracy: 0.9686\n",
            "Epoch 70/100\n",
            "136/136 [==============================] - 26s 194ms/step - loss: 0.1158 - categorical_accuracy: 0.9591 - val_loss: 0.1240 - val_categorical_accuracy: 0.9680\n",
            "Epoch 71/100\n",
            "136/136 [==============================] - 26s 195ms/step - loss: 0.1139 - categorical_accuracy: 0.9617 - val_loss: 0.1235 - val_categorical_accuracy: 0.9686\n",
            "\n",
            "Epoch 00071: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
            "Epoch 72/100\n",
            "136/136 [==============================] - 26s 193ms/step - loss: 0.1452 - categorical_accuracy: 0.9541 - val_loss: 0.1216 - val_categorical_accuracy: 0.9692\n",
            "Epoch 73/100\n",
            "136/136 [==============================] - 26s 193ms/step - loss: 0.1292 - categorical_accuracy: 0.9536 - val_loss: 0.1206 - val_categorical_accuracy: 0.9686\n",
            "Epoch 74/100\n",
            "136/136 [==============================] - 26s 194ms/step - loss: 0.0988 - categorical_accuracy: 0.9670 - val_loss: 0.1224 - val_categorical_accuracy: 0.9674\n",
            "Epoch 75/100\n",
            "136/136 [==============================] - 26s 194ms/step - loss: 0.1362 - categorical_accuracy: 0.9520 - val_loss: 0.1223 - val_categorical_accuracy: 0.9686\n",
            "Epoch 76/100\n",
            "136/136 [==============================] - 27s 195ms/step - loss: 0.1113 - categorical_accuracy: 0.9649 - val_loss: 0.1232 - val_categorical_accuracy: 0.9686\n",
            "Epoch 77/100\n",
            "136/136 [==============================] - 26s 194ms/step - loss: 0.1104 - categorical_accuracy: 0.9628 - val_loss: 0.1247 - val_categorical_accuracy: 0.9674\n",
            "Epoch 78/100\n",
            "136/136 [==============================] - 26s 193ms/step - loss: 0.1024 - categorical_accuracy: 0.9674 - val_loss: 0.1232 - val_categorical_accuracy: 0.9686\n",
            "\n",
            "Epoch 00078: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
            "Epoch 79/100\n",
            "136/136 [==============================] - 26s 194ms/step - loss: 0.1274 - categorical_accuracy: 0.9652 - val_loss: 0.1197 - val_categorical_accuracy: 0.9680\n",
            "Epoch 80/100\n",
            "136/136 [==============================] - 26s 193ms/step - loss: 0.1294 - categorical_accuracy: 0.9604 - val_loss: 0.1243 - val_categorical_accuracy: 0.9668\n",
            "Epoch 81/100\n",
            "136/136 [==============================] - 26s 194ms/step - loss: 0.1247 - categorical_accuracy: 0.9616 - val_loss: 0.1215 - val_categorical_accuracy: 0.9692\n",
            "Epoch 82/100\n",
            "136/136 [==============================] - 27s 195ms/step - loss: 0.1176 - categorical_accuracy: 0.9651 - val_loss: 0.1232 - val_categorical_accuracy: 0.9674\n",
            "Epoch 83/100\n",
            "136/136 [==============================] - 27s 195ms/step - loss: 0.1263 - categorical_accuracy: 0.9608 - val_loss: 0.1212 - val_categorical_accuracy: 0.9680\n",
            "Epoch 84/100\n",
            "136/136 [==============================] - 26s 194ms/step - loss: 0.1212 - categorical_accuracy: 0.9584 - val_loss: 0.1232 - val_categorical_accuracy: 0.9680\n",
            "Epoch 85/100\n",
            "136/136 [==============================] - 27s 195ms/step - loss: 0.1148 - categorical_accuracy: 0.9620 - val_loss: 0.1225 - val_categorical_accuracy: 0.9680\n",
            "\n",
            "Epoch 00085: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
            "Epoch 86/100\n",
            "136/136 [==============================] - 26s 194ms/step - loss: 0.1212 - categorical_accuracy: 0.9595 - val_loss: 0.1225 - val_categorical_accuracy: 0.9680\n",
            "Epoch 87/100\n",
            "136/136 [==============================] - 26s 195ms/step - loss: 0.1232 - categorical_accuracy: 0.9572 - val_loss: 0.1226 - val_categorical_accuracy: 0.9680\n",
            "Epoch 88/100\n",
            "136/136 [==============================] - 26s 194ms/step - loss: 0.1193 - categorical_accuracy: 0.9605 - val_loss: 0.1208 - val_categorical_accuracy: 0.9686\n",
            "Epoch 89/100\n",
            "136/136 [==============================] - 27s 195ms/step - loss: 0.1165 - categorical_accuracy: 0.9572 - val_loss: 0.1238 - val_categorical_accuracy: 0.9680\n",
            "Epoch 90/100\n",
            "136/136 [==============================] - 26s 191ms/step - loss: 0.1190 - categorical_accuracy: 0.9632 - val_loss: 0.1237 - val_categorical_accuracy: 0.9668\n",
            "Epoch 91/100\n",
            "136/136 [==============================] - 26s 192ms/step - loss: 0.1229 - categorical_accuracy: 0.9570 - val_loss: 0.1225 - val_categorical_accuracy: 0.9674\n",
            "Epoch 92/100\n",
            "136/136 [==============================] - 26s 192ms/step - loss: 0.1224 - categorical_accuracy: 0.9599 - val_loss: 0.1230 - val_categorical_accuracy: 0.9680\n",
            "\n",
            "Epoch 00092: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
            "Epoch 93/100\n",
            "136/136 [==============================] - 26s 192ms/step - loss: 0.1233 - categorical_accuracy: 0.9573 - val_loss: 0.1186 - val_categorical_accuracy: 0.9686\n",
            "Epoch 94/100\n",
            "136/136 [==============================] - 26s 192ms/step - loss: 0.1159 - categorical_accuracy: 0.9621 - val_loss: 0.1216 - val_categorical_accuracy: 0.9686\n",
            "Epoch 95/100\n",
            "136/136 [==============================] - 26s 190ms/step - loss: 0.1208 - categorical_accuracy: 0.9573 - val_loss: 0.1205 - val_categorical_accuracy: 0.9692\n",
            "Epoch 96/100\n",
            "136/136 [==============================] - 26s 191ms/step - loss: 0.1201 - categorical_accuracy: 0.9560 - val_loss: 0.1232 - val_categorical_accuracy: 0.9680\n",
            "Epoch 97/100\n",
            "136/136 [==============================] - 26s 191ms/step - loss: 0.1208 - categorical_accuracy: 0.9594 - val_loss: 0.1255 - val_categorical_accuracy: 0.9680\n",
            "Epoch 98/100\n",
            "136/136 [==============================] - 26s 190ms/step - loss: 0.1147 - categorical_accuracy: 0.9641 - val_loss: 0.1232 - val_categorical_accuracy: 0.9686\n",
            "Epoch 99/100\n",
            "136/136 [==============================] - 26s 191ms/step - loss: 0.1181 - categorical_accuracy: 0.9642 - val_loss: 0.1224 - val_categorical_accuracy: 0.9680\n",
            "\n",
            "Epoch 00099: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
            "Epoch 100/100\n",
            "136/136 [==============================] - 26s 190ms/step - loss: 0.1125 - categorical_accuracy: 0.9662 - val_loss: 0.1223 - val_categorical_accuracy: 0.9680\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}